# -*- coding: utf-8 -*-
"""PCA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D99jCBSFgZXRwf1cU0KVrlfxHQ9v08nB
"""

import numpy as np
import pandas as pd
import time
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from sklearn.base import BaseEstimator, TransformerMixin
from scipy.stats.mstats import winsorize
from google.colab import drive


def winsorize_df(df):
    df_copy = df.copy()
    for col in df_copy.columns:
        if pd.api.types.is_numeric_dtype(df_copy[col]):
            df_copy[col] = winsorize(df_copy[col], limits=[0.05, 0.05])
    return df_copy

class Winsorizer(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        return self
    def transform(self, X):
        return winsorize_df(pd.DataFrame(X)).values

class HardClipper(BaseEstimator, TransformerMixin):
    RANGES = {'age': (25, 65), 'height': (130, 210), 'weight': (40, 150),
              'ap_hi': (80, 250), 'ap_lo': (50, 140)}

    def fit(self, X, y=None):
        self.feature_names_in_ = list(self.RANGES.keys())
        return self # Corrected 'this' to 'self'

    def transform(self, X):
        X_df = pd.DataFrame(X, columns=self.feature_names_in_)
        for col, (low, high) in self.RANGES.items():
            X_df[col] = np.clip(X_df[col], low, high)
        return X_df.values


drive.mount('/content/drive', force_remount=True)
df = pd.read_csv("/content/drive/MyDrive/dataset/datasetsinprepro2.csv")

target = "cardio"
y = df[target]
X = df.drop(columns=[target])

numeric_features = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']
others = ['cholesterol', 'gluc', 'gender', 'smoke', 'alco', 'active']


preprocessor = ColumnTransformer([
    ('numeric', Pipeline([
        ('clip', HardClipper()),
        ('impute', SimpleImputer(strategy='mean')),
        ('winsor', Winsorizer()),
        ('scale', StandardScaler())
    ]), numeric_features),

    ('others', SimpleImputer(strategy='most_frequent'), others)
])



components_list = [11, 10, 9, 5, 3]
seeds = [42, 7, 21, 99, 12345]

results = []


for n_comp in components_list:
    for seed in seeds:

        # Split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, stratify=y, random_state=seed
        )

        # Preprocesar
        X_train_prep = preprocessor.fit_transform(X_train)
        X_test_prep = preprocessor.transform(X_test)

        # SMOTE
        X_train_bal, y_train_bal = SMOTE(random_state=seed).fit_resample(
            X_train_prep, y_train
        )

        # PCA
        pca = PCA(n_components=n_comp, random_state=seed)
        X_train_pca = pca.fit_transform(X_train_bal)
        X_test_pca = pca.transform(X_test_prep)

        # Modelo
        model = LogisticRegression(max_iter=1000, solver="liblinear")

        t0 = time.time()
        model.fit(X_train_pca, y_train_bal)
        train_time = time.time() - t0

        # Predicciones
        y_pred = model.predict(X_test_pca)
        y_proba = model.predict_proba(X_test_pca)[:, 1]

        # Guardar resultados
        results.append({
            "n_components": n_comp,
            "seed": seed,
            "accuracy": accuracy_score(y_test, y_pred),
            "precision": precision_score(y_test, y_pred, zero_division=0),
            "recall": recall_score(y_test, y_pred, zero_division=0),
            "f1": f1_score(y_test, y_pred, zero_division=0),
            "auc": roc_auc_score(y_test, y_proba),
            "explained_variance_cum": pca.explained_variance_ratio_.sum(),
            "train_time_s": train_time
        })

res_df = pd.DataFrame(results)

summary = (
    res_df.drop(columns=["seed"])
          .groupby("n_components")
          .agg(["mean","std"])
          .round(4)
)


print(summary)